# -*- coding: utf-8 -*-
"""ClasseMultiTeste.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n7dFs9oysBihRC_XlnkVLcxUbeaIi596
"""

import warnings
warnings.filterwarnings('ignore')

#Apoio
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import model_selection

#Algoritmos classificadores
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import ExtraTreeClassifier
from sklearn.multioutput import ClassifierChain
from sklearn.multioutput import MultiOutputClassifier
from sklearn.multiclass import OutputCodeClassifier
from sklearn.multiclass import OneVsOneClassifier
from sklearn.multiclass import OneVsRestClassifier
from sklearn.naive_bayes import BernoulliNB
from sklearn.calibration import CalibratedClassifierCV
from sklearn.naive_bayes import GaussianNB
from sklearn.semi_supervised import LabelPropagation
from sklearn.semi_supervised import LabelSpreading
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LogisticRegressionCV
from sklearn.naive_bayes import MultinomialNB  
from sklearn.neighbors import NearestCentroid
from sklearn.linear_model import Perceptron
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.mixture import GaussianMixture
from sklearn.svm import LinearSVC, NuSVC, SVC
from sklearn.linear_model import SGDClassifier
from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, RandomForestClassifier, AdaBoostClassifier
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import GradientBoostingClassifier
from lightgbm import LGBMClassifier
from sklearn.linear_model import SGDClassifier

#algoritmos regressores
from sklearn.linear_model import LinearRegression
from lightgbm import LGBMRegressor
from sklearn.linear_model import SGDRegressor
from sklearn.kernel_ridge import KernelRidge
from sklearn.linear_model import ElasticNet
from sklearn.linear_model import BayesianRidge
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor

#Apoio especifico
from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, recall_score, precision_score
from sklearn.metrics import mean_squared_error,mean_absolute_error#, root_mean_squared_error
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.gaussian_process.kernels import RBF
from sklearn.preprocessing import LabelBinarizer
from sklearn import preprocessing

class MultiTeste:

    classificadores = [
        SVC(gamma='auto'),
        GaussianProcessClassifier(1.0 * RBF(1.0)),
        LinearSVC(),
        SGDClassifier(max_iter=100, tol=1e-3), 
        KNeighborsClassifier(),
        LogisticRegression(solver='lbfgs'), 
        LogisticRegressionCV(cv=3),
        BaggingClassifier(), 
        ExtraTreesClassifier(n_estimators=300),
        RandomForestClassifier(max_depth=5, n_estimators=300, max_features=1),
        GaussianNB(), 
        DecisionTreeClassifier(max_depth=5),
        MLPClassifier(alpha=1, max_iter=1000),
        AdaBoostClassifier(),
        LinearDiscriminantAnalysis(),
        QuadraticDiscriminantAnalysis(),
        OneVsRestClassifier(LinearSVC(random_state=0)), #multiclass
        LGBMClassifier(),
        GradientBoostingClassifier(),
        SGDClassifier(),

    ]

    regressores = [
        LinearRegression(),
        LGBMRegressor(),
        SGDRegressor(),
        KernelRidge(),
        ElasticNet(),
        BayesianRidge(),
        GradientBoostingRegressor(),
        SVR(),
        MLPRegressor()
    ]
####
   # def __init__(self, X, y, tipoDado):
   #     self.X = preprocessing.normalize(X, norm='l2')
   #     self.y = y
   #     self.tipoDado = tipoDado
   #     if self.tipoDado == 'multiclasse':
   #         self.y = LabelBinarizer().fit_transform(y)
###
    def __init__(self, X_treino, y_treino, X_teste, y_teste, tipoDado):
        self.X_treino = preprocessing.normalize(X_treino, norm='l2')
        self.X_teste = preprocessing.normalize(X_teste, norm='l2')
        self.y_treino = y_treino
        self.y_teste = y_teste
        self.tipoDado = tipoDado
        if self.tipoDado == 'multiclasse':
            self.y_treino = LabelBinarizer().fit_transform(y_treino)
            self.y_teste = LabelBinarizer().fit_transform(y_teste)

    ##
    # Função que executa todos os testes de Classificação. 
    # Ao instanciar a classe, informar no parametro
    # tipoDado se é 'binaria' ou 'multiclasse'. Isso fará
    # o tratamento correto do vetor y para o case de multiplas 
    # categorias de classificação. A saída da função é o um dataframe
    # com os resultados.
    ##  
    def Classificacao(self):
        seed = 10
        splits = 10
        qtd_modelos = 0
        algoritmos = []
        acuracia = []
        #roc_auc = []
        revogacao = []
        precisao = []
        f1 = []
        resultados = pd.DataFrame(columns=['algoritmo','acurácia', 'revogação', 'precisão', 'f1'])
        metricas_class = ['accuracy', 'recall', 'precision', 'f1']
        
        for modelo in self.classificadores:
            print(f"Processando {modelo.__class__.__name__}")
            qtd_modelos += 1
            kfold = model_selection.KFold(n_splits=splits, random_state=seed, shuffle=True)
            algoritmos.append(modelo.__class__.__name__)
            qual_metrica = 0
            for metrica in metricas_class:
                cv_results = model_selection.cross_val_score(modelo, self.X_treino, self.y_treino, cv=kfold, scoring=metrica)
                if qual_metrica == 0:
                    acuracia.append(cv_results.mean())
                if qual_metrica == 1:
                    revogacao.append(cv_results.mean())
                if qual_metrica == 2:
                    precisao.append(cv_results.mean())
                if qual_metrica == 3:
                    f1.append(cv_results.mean())
                qual_metrica += 1
        print("Fim de Processamento.")

        resultados['algoritmo'] = algoritmos
        #resultados['roc_auc'] = roc_auc
        resultados['acurácia'] = acuracia
        resultados['revogação'] = revogacao
        resultados['precisão'] = precisao
        resultados['f1'] = f1
        return resultados
    
    def ClassificadorMedico(self):
        qtd_modelos = 0
        algoritmos = []
        acuracia = []
        roc_auc = []
        revogacao = []
        precisao = []
        f1 = []
        resultados = pd.DataFrame(columns=['algoritmo','f1','acurácia', 'roc_auc', 'revogação', 'precisão'])
        metricas_class = [f1_score, accuracy_score, roc_auc_score, recall_score, precision_score]
                    
        for modelo in self.regressores:
            print(f"Processando {modelo.__class__.__name__}")
            qtd_modelos += 1
            #kfold = model_selection.KFold(n_splits=splits, random_state=seed, shuffle=True)
            algoritmos.append(modelo.__class__.__name__)
            qual_metrica = 0
            for metrica in metricas_class:
                resultado_treino, resultado_teste = self.avaliaClassificadorExames(modelo, self.X_treino, self.y_treino, 
                                                                                   self.X_teste, self.y_teste, metrica)
                if qual_metrica == 0:
                    f1.append(resultado_teste)
                if qual_metrica == 1:
                    acuracia.append(resultado_teste)
                if qual_metrica == 2:
                    roc_auc.append(resultado_teste)
                if qual_metrica == 3:
                    revogacao.append(resultado_teste)
                if qual_metrica == 4:
                    precisao.append(resultado_teste)
                qual_metrica += 1
        print("Fim de Processamento.")

        resultados['algoritmo'] = algoritmos
        resultados['roc_auc'] = roc_auc
        resultados['acurácia'] = acuracia
        resultados['revogação'] = revogacao
        resultados['precisão'] = precisao
        resultados['f1'] = f1
        return resultados

    def F1_score(self, revocacao, precisao):
        return 2*(revocacao*precisao)/(revocacao+precisao)
    
    def metricasBasicas(self, y_original, y_previsto):
        falsoPositivo = 0
        verdadeiroPositivo = 0
        falsoNegativo = 0
        verdadeiroNegativo = 0
        for x in range(y_original.shape[0]):
            if y_original[x] == 0:
                if y_previsto[x] == 0:
                    verdadeiroNegativo = verdadeiroNegativo + 1
                else:
                    falsoNegativo = falsoNegativo + 1
            if y_original[x] == 1:
                if y_previsto[x] == 1:
                    verdadeiroPositivo = verdadeiroPositivo + 1
                else:
                    falsoPositivo = falsoPositivo + 1
    
        return falsoPositivo, verdadeiroPositivo, falsoNegativo, verdadeiroNegativo

    def formataSaida(self, valor):
        saidaFormatada = "{:.2f}".format(valor*100)
        return saidaFormatada + "%"
    
    ## Avaliador padrão
    def avaliaClassificadorGeral(self, clf, kf, X, y, f_metrica):
        metrica_val = []
        metrica_train = []
        for train, valid in kf.split(X,y):
            x_train = X[train]
            y_train = y[train]
            x_valid = X[valid]
            y_valid = y[valid]
            clf.fit(x_train, y_train)
            y_pred_val = clf.predict(x_valid)
            y_pred_train = clf.predict(x_train)
            metrica_val.append(f_metrica(y_valid, y_pred_val))
            metrica_train.append(f_metrica(y_train, y_pred_train))
        return np.array(metrica_val).mean(), np.array(metrica_train).mean()

    ## Avaliador considerando exames médicos
    # Não há rodadas de cross validation pq não há
    # como garantir a separação correta de exames e pacientes.
    def avaliaClassificadorExames(self, clf, X_treino, y_treino, X_teste, y_teste, f_metrica):
        #metrica_val = []
        #metrica_train = []
        clf.fit(X_treino, y_treino)
        y_pred_val = clf.predict(X_teste)
        y_pred_train = clf.predict(X_treino)
        metrica_teste = f_metrica(y_teste, y_pred_val)
        metrica_treino = f_metrica(y_treino, y_pred_train)
        return metrica_treino, metrica_teste

    def apresentaMetrica(self, nome_metrica, metrica_val, metrica_train, percentual = False):
        c = 100.0 if percentual else 1.0
        print('{} (validação): {}{}'.format(nome_metrica, metrica_val * c, '%' if percentual else ''))
        print('{} (treino): {}{}'.format(nome_metrica, metrica_train * c, '%' if percentual else ''))


    ##
    # Função para ordenar pela métrica a saída da Função Teste. 
    # Não faz sentido ser usada antes desta função.
    # O parametro 'metrica' é uma string e assume os valores
    # 'accuracy', 'recall', 'precision', 'f1', 'MAE', 'MSE' ou 'RMSE'
    ##
    def OrdenaMetrica(self, saida, metrica):
        self.saida = saida
        return self.saida.sort_values(metrica, ascending=True, ignore_index=True)

    def Regressao(self):
        seed = 10
        splits = 10
        qtd_modelos = 0
        algoritmos = []
        MSE = []
        MAE = []
        RMSE = []
        resultados = pd.DataFrame(columns=['algoritmo','MSE', 'MAE', 'RMSE'])
        metricas_reg = ['neg_mean_squared_error','neg_mean_absolute_error','neg_root_mean_squared_error']
        
        for modelo in self.regressores:
            print(f"Processando {modelo.__class__.__name__}")
            qtd_modelos += 1
            kfold = model_selection.KFold(n_splits=splits, random_state=seed, shuffle=True)
            algoritmos.append(modelo.__class__.__name__)
            qual_metrica = 0
            for metrica in metricas_reg:
                cv_results = model_selection.cross_val_score(modelo, self.X, self.y, cv=kfold, scoring=metrica)
                if qual_metrica == 0:
                    MSE.append(cv_results.mean())
                if qual_metrica == 1:
                    MAE.append(cv_results.mean())
                if qual_metrica == 2:
                    RMSE.append(cv_results.mean())
                qual_metrica += 1
        print("Fim de Processamento.")

        resultados['algoritmo'] = algoritmos
        resultados['MSE'] = MSE
        resultados['MAE'] = MAE
        resultados['RMSE'] = RMSE
        return resultados

    def RegressaoMedica(self):
        qtd_modelos = 0
        algoritmos = []
        MSE = []
        MAE = []
        RMSE = []
        resultados = pd.DataFrame(columns=['algoritmo','MSE', 'MAE', 'RMSE'])
        #metricas_reg = ['neg_mean_squared_error','neg_mean_absolute_error','neg_root_mean_squared_error']
        metricas_reg = [mean_squared_error,mean_absolute_error]#,root_mean_squared_error]
        
        for modelo in self.regressores:
            print(f"Processando {modelo.__class__.__name__}")
            qtd_modelos += 1
            #kfold = model_selection.KFold(n_splits=splits, random_state=seed, shuffle=True)
            algoritmos.append(modelo.__class__.__name__)
            qual_metrica = 0
            for metrica in metricas_reg:
                resultado_treino, resultado_teste = self.avaliaClassificadorExames(modelo, self.X_treino, self.y_treino, 
                                                                                   self.X_teste, self.y_teste, metrica)
                if qual_metrica == 0:
                    MSE.append(resultado_teste)
                    RMSE.append(np.sqrt(resultado_teste))
                if qual_metrica == 1:
                    MAE.append(resultado_teste)
                #if qual_metrica == 2:
                #   RMSE.append(resultado_teste)
                qual_metrica += 1
        print("Fim de Processamento.")

        resultados['algoritmo'] = algoritmos
        resultados['MSE'] = MSE
        resultados['MAE'] = MAE
        resultados['RMSE'] = RMSE
        return resultados

